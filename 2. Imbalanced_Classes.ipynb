{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced_Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to take\n",
    "<font color='grey'>step 1: Import all the necessary python packages</font><br>\n",
    "<font color='grey'>step 2: Obtain and clean data</font> <br>\n",
    "<font color='grey'>step 3: Data Exploration</font> <br>\n",
    "<font color='grey'>step 4: Modify data for Machine Learning</font><br>\n",
    "<font color='grey'>step 5: Get dummies</font><br>\n",
    "<font color='grey'>step 6: Split data into train and test</font><br> \n",
    "step 6: Standard scaling<br>\n",
    "step 7: Dealing with Imbalanced Data:\n",
    "- Logistic Regression \"class_weight\" parameter\n",
    "- SMOTE (oversampling)\n",
    "- Undersampling\n",
    "\n",
    "step 8: logistic regression<br>\n",
    "<font color='grey'>step 9: parameter tuning</font><br>\n",
    "<font color='grey'>step 10: provide actionable recommendations</font><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', size=14)\n",
    "import seaborn as sns \n",
    "# sns.set(style='white')\n",
    "# sns.set(style='whitegrid', color_codes=True)\n",
    "\n",
    "#Machine Learning Modules\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix#, classifiction_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
    "\n",
    "# autoreload \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#logistic regression script\n",
    "import logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'campaign', 'pdays', 'previous', 'job_blue-collar',\n",
       "       'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired',\n",
       "       'job_self-employed', 'job_services', 'job_student', 'job_technician',\n",
       "       'job_unemployed', 'job_unknown', 'marital_married', 'marital_single',\n",
       "       'marital_unknown', 'education_high.school', 'education_illiterate',\n",
       "       'education_professional.course', 'education_university.degree',\n",
       "       'education_unknown', 'housing_unknown', 'housing_yes',\n",
       "       'default_unknown', 'default_yes', 'loan_unknown', 'loan_yes',\n",
       "       'contact_telephone', 'month_aug', 'month_dec', 'month_jul', 'month_jun',\n",
       "       'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sep',\n",
       "       'day_of_week_mon', 'day_of_week_thu', 'day_of_week_tue',\n",
       "       'day_of_week_wed', 'poutcome_nonexistent', 'poutcome_success'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load Train data from data/Train\n",
    "Train = pd.read_csv('data/Train.csv',)\n",
    "\n",
    "X_train = Train.drop('target', axis = 1)\n",
    "y_train = Train['target']\n",
    "\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32940, 45)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_self-employed</th>\n",
       "      <th>...</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>day_of_week_mon</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "      <th>poutcome_nonexistent</th>\n",
       "      <th>poutcome_success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.293135</td>\n",
       "      <td>-0.564625</td>\n",
       "      <td>-0.19645</td>\n",
       "      <td>1.679762</td>\n",
       "      <td>-0.539824</td>\n",
       "      <td>-0.191649</td>\n",
       "      <td>-0.165773</td>\n",
       "      <td>-0.273916</td>\n",
       "      <td>-0.209108</td>\n",
       "      <td>-0.190026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.709185</td>\n",
       "      <td>-0.333783</td>\n",
       "      <td>-0.129585</td>\n",
       "      <td>-0.119922</td>\n",
       "      <td>-0.511124</td>\n",
       "      <td>-0.515608</td>\n",
       "      <td>-0.494967</td>\n",
       "      <td>-0.494729</td>\n",
       "      <td>-2.511053</td>\n",
       "      <td>-0.186655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.676809</td>\n",
       "      <td>-0.204519</td>\n",
       "      <td>-0.19645</td>\n",
       "      <td>-0.350523</td>\n",
       "      <td>-0.539824</td>\n",
       "      <td>-0.191649</td>\n",
       "      <td>-0.165773</td>\n",
       "      <td>-0.273916</td>\n",
       "      <td>-0.209108</td>\n",
       "      <td>-0.190026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.709185</td>\n",
       "      <td>-0.333783</td>\n",
       "      <td>-0.129585</td>\n",
       "      <td>-0.119922</td>\n",
       "      <td>-0.511124</td>\n",
       "      <td>-0.515608</td>\n",
       "      <td>2.020338</td>\n",
       "      <td>-0.494729</td>\n",
       "      <td>0.398239</td>\n",
       "      <td>-0.186655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.676809</td>\n",
       "      <td>-0.564625</td>\n",
       "      <td>-0.19645</td>\n",
       "      <td>-0.350523</td>\n",
       "      <td>-0.539824</td>\n",
       "      <td>-0.191649</td>\n",
       "      <td>-0.165773</td>\n",
       "      <td>-0.273916</td>\n",
       "      <td>-0.209108</td>\n",
       "      <td>-0.190026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.709185</td>\n",
       "      <td>-0.333783</td>\n",
       "      <td>-0.129585</td>\n",
       "      <td>-0.119922</td>\n",
       "      <td>-0.511124</td>\n",
       "      <td>-0.515608</td>\n",
       "      <td>2.020338</td>\n",
       "      <td>-0.494729</td>\n",
       "      <td>0.398239</td>\n",
       "      <td>-0.186655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.197216</td>\n",
       "      <td>0.155587</td>\n",
       "      <td>-0.19645</td>\n",
       "      <td>-0.350523</td>\n",
       "      <td>-0.539824</td>\n",
       "      <td>-0.191649</td>\n",
       "      <td>-0.165773</td>\n",
       "      <td>-0.273916</td>\n",
       "      <td>-0.209108</td>\n",
       "      <td>-0.190026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.709185</td>\n",
       "      <td>-0.333783</td>\n",
       "      <td>-0.129585</td>\n",
       "      <td>-0.119922</td>\n",
       "      <td>1.956473</td>\n",
       "      <td>-0.515608</td>\n",
       "      <td>-0.494967</td>\n",
       "      <td>-0.494729</td>\n",
       "      <td>0.398239</td>\n",
       "      <td>-0.186655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.090540</td>\n",
       "      <td>-0.564625</td>\n",
       "      <td>-0.19645</td>\n",
       "      <td>-0.350523</td>\n",
       "      <td>-0.539824</td>\n",
       "      <td>-0.191649</td>\n",
       "      <td>-0.165773</td>\n",
       "      <td>-0.273916</td>\n",
       "      <td>-0.209108</td>\n",
       "      <td>-0.190026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.709185</td>\n",
       "      <td>-0.333783</td>\n",
       "      <td>-0.129585</td>\n",
       "      <td>-0.119922</td>\n",
       "      <td>1.956473</td>\n",
       "      <td>-0.515608</td>\n",
       "      <td>-0.494967</td>\n",
       "      <td>-0.494729</td>\n",
       "      <td>0.398239</td>\n",
       "      <td>-0.186655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  campaign    pdays  previous  job_blue-collar  job_entrepreneur  \\\n",
       "0 -0.293135 -0.564625 -0.19645  1.679762        -0.539824         -0.191649   \n",
       "1 -0.676809 -0.204519 -0.19645 -0.350523        -0.539824         -0.191649   \n",
       "2 -0.676809 -0.564625 -0.19645 -0.350523        -0.539824         -0.191649   \n",
       "3 -0.197216  0.155587 -0.19645 -0.350523        -0.539824         -0.191649   \n",
       "4  0.090540 -0.564625 -0.19645 -0.350523        -0.539824         -0.191649   \n",
       "\n",
       "   job_housemaid  job_management  job_retired  job_self-employed  ...  \\\n",
       "0      -0.165773       -0.273916    -0.209108          -0.190026  ...   \n",
       "1      -0.165773       -0.273916    -0.209108          -0.190026  ...   \n",
       "2      -0.165773       -0.273916    -0.209108          -0.190026  ...   \n",
       "3      -0.165773       -0.273916    -0.209108          -0.190026  ...   \n",
       "4      -0.165773       -0.273916    -0.209108          -0.190026  ...   \n",
       "\n",
       "   month_may  month_nov  month_oct  month_sep  day_of_week_mon  \\\n",
       "0  -0.709185  -0.333783  -0.129585  -0.119922        -0.511124   \n",
       "1  -0.709185  -0.333783  -0.129585  -0.119922        -0.511124   \n",
       "2  -0.709185  -0.333783  -0.129585  -0.119922        -0.511124   \n",
       "3  -0.709185  -0.333783  -0.129585  -0.119922         1.956473   \n",
       "4  -0.709185  -0.333783  -0.129585  -0.119922         1.956473   \n",
       "\n",
       "   day_of_week_thu  day_of_week_tue  day_of_week_wed  poutcome_nonexistent  \\\n",
       "0        -0.515608        -0.494967        -0.494729             -2.511053   \n",
       "1        -0.515608         2.020338        -0.494729              0.398239   \n",
       "2        -0.515608         2.020338        -0.494729              0.398239   \n",
       "3        -0.515608        -0.494967        -0.494729              0.398239   \n",
       "4        -0.515608        -0.494967        -0.494729              0.398239   \n",
       "\n",
       "   poutcome_success  \n",
       "0         -0.186655  \n",
       "1         -0.186655  \n",
       "2         -0.186655  \n",
       "3         -0.186655  \n",
       "4         -0.186655  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "columns = X_train.columns\n",
    "\n",
    "scaled_train = scaler.transform(X_train)\n",
    "X_train_scaled = pd.DataFrame(scaled_train, columns=columns)\n",
    "# ## then used \n",
    "# # scaler.transform(X_test)\n",
    "print(X_train_scaled.shape)\n",
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logreg_sample = LogisticRegression(C=1e9, solver='newton-cg')\n",
    "# logreg_sample.fit(X_train_scaled, y_train)\n",
    "# y_hat_new = logreg_sample.predict(X=X_train_scaled)\n",
    "# y_hat_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7.0: No treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without class weight \n",
    "logreg_baseline = LogisticRegression(C = 1e9, solver='newton-cg')\n",
    "logreg_baseline.fit(X_train_scaled, y_train)\n",
    "y_hat_vanilla_baseline = logreg_baseline.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.8976927747419551\n",
      "precision = 0.66\n",
      "recall = 0.19\n",
      "accuracy = 0.66\n",
      "f1 score = 0.29\n"
     ]
    }
   ],
   "source": [
    "print(f\"score = {logreg_baseline.score(scaled_train, y_train)}\")\n",
    "logistic_regression.print_metrics(y_train, y_hat_vanilla_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7.1: No treatment, using class_weight parameter in sklearn LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.8030358227079538\n",
      "precision = 0.3\n",
      "recall = 0.57\n",
      "accuracy = 0.3\n",
      "f1 score = 0.4\n"
     ]
    }
   ],
   "source": [
    "logreg_base_classweight = LogisticRegression(C = 1e9, class_weight='balanced', solver='newton-cg')\n",
    "logreg_base_classweight.fit(X_train_scaled, y_train)\n",
    "y_hat_base_classweight = logreg_base_classweight.predict(X_train_scaled)\n",
    "\n",
    "print(f\"score = {logreg_base_classweight.score(X_train_scaled, y_train)}\")\n",
    "logistic_regression.print_metrics(y_train, y_hat_base_classweight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting - The model score decreased.<br>\n",
    "Our recall and f1 score look better, but we should try other methods. <br>\n",
    "\n",
    "Next we will try resampling the data using two different methods:\n",
    "    - Oversampling with synthetic data (SMOTE)\n",
    "    - Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7.2: Using SMOTE \n",
    "Here we try to up-sample the subscription class (minority) using the SMOTE algorithm(Synthetic Minority Oversampling Techique).<br>\n",
    "It works by creating synthetic samples from the minor class (no-subscription) instead of creating copies.\n",
    "Randomly choosing one of the k-nearest-neighbors and using it to create a similar, but randomly tweaked, new observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of oversampled data is 58458\n",
      "Number of no subscription in oversampled data 29229\n",
      "Number of subscription 29229\n",
      "Proportion of no subscription data in oversampled data is 0.5\n",
      "Proportion of subscription data in oversampled data is 0.5\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "# columns = scaled_train.columns\n",
    "\n",
    "os = SMOTE(random_state=19)\n",
    "os_data_X, os_data_y = os.fit_sample(X_train_scaled, y_train)\n",
    "os_data_X = pd.DataFrame(data=os_data_X, columns=columns)\n",
    "# os_data_y = pd.Series(os_data_y)\n",
    "os_y=os_data_y.reshape(-1, 1)\n",
    "\n",
    "# check numbers\n",
    "print('Length of oversampled data is', len(os_data_X))\n",
    "print('Number of no subscription in oversampled data', np.sum(os_data_y==0))\n",
    "print('Number of subscription', np.sum(os_data_y==1))\n",
    "print('Proportion of no subscription data in oversampled data is', np.sum(os_data_y==0)/len(os_data_y))\n",
    "print('Proportion of subscription data in oversampled data is', np.sum(os_data_y==1)/len(os_data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(bank_clean['target'].value_counts(normalize=True))\n",
    "c=sns.countplot(x=os_data_y, palette='hls')#, data=bank_clean, palette='hls', )\n",
    "plt.xlabel('Subscription')\n",
    "c.set_xticklabels(['fail','success']);\n",
    "\n",
    "plt.savefig('img/count_plot_SMOTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58458, 45)\n",
      "(58458,)\n",
      "(58458, 1)\n"
     ]
    }
   ],
   "source": [
    "# after using Synthetic Minority Oversampling Techique\n",
    "print(os_data_X.shape)\n",
    "print(os_data_y.shape)\n",
    "print(os_y.shape)\n",
    "# os_data_y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.708183653221116\n",
      "precision = 0.75\n",
      "recall = 0.62\n",
      "accuracy = 0.75\n",
      "f1 score = 0.68\n"
     ]
    }
   ],
   "source": [
    "#Perform vanilla logistic regression\n",
    "logreg_base_SMOTE = LogisticRegression(C = 1e9, class_weight='balanced', solver='newton-cg')\n",
    "logreg_base_SMOTE.fit(os_data_X, os_data_y)\n",
    "y_hat_base_SMOTE = logreg_base_SMOTE.predict(os_data_X)\n",
    "\n",
    "print(f\"score = {logreg_base_SMOTE.score(os_data_X, os_data_y)}\")\n",
    "logistic_regression.print_metrics(os_data_y, y_hat_base_SMOTE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model score decreased again from 0.8 to 0.7.<br>\n",
    "However, the SMOTE method seems to increase all our metric scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7.3: Using undersampling technique\n",
    "This technique undersamples the majority class randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success original count: 3711\n",
      "failure original count: 29229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    3711\n",
       "0    3711\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# concatenate our training data back together\n",
    "X = pd.concat([X_train_scaled, y_train], axis=1)\n",
    "X.head()\n",
    "# separate minority and majority classes\n",
    "success = X[X.target==1]\n",
    "failure = X[X.target==0]\n",
    "print(f\"success original count: {len(success)}\")\n",
    "print(f\"failure original count: {len(failure)}\")\n",
    "\n",
    "# downsample majority\n",
    "failure_downsampled = resample(failure,\n",
    "                               replace = False, # sample without replacement\n",
    "                               n_samples = len(success), # match minority n\n",
    "                               random_state = 19) # reproducible results\n",
    "\n",
    "# combine minority and downsampled majority\n",
    "downsampled = pd.concat([failure_downsampled, success])\n",
    "\n",
    "# checking counts\n",
    "downsampled.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.7012934518997574\n",
      "precision = 0.77\n",
      "recall = 0.58\n",
      "accuracy = 0.77\n",
      "f1 score = 0.66\n"
     ]
    }
   ],
   "source": [
    "# Trying vanilla logistic regression again with the balanced dataset\n",
    "y_train_undersample = downsampled['target']\n",
    "X_train_undersample = downsampled.drop('target', axis=1)\n",
    "\n",
    "downsampled_lr = LogisticRegression(C = 1e9, solver='newton-cg',class_weight='balanced',max_iter=1000)\n",
    "downsampled_lr.fit(X_train_undersample, y_train_undersample)\n",
    "\n",
    "downsampled_pred = downsampled_lr.predict(X_train_undersample)\n",
    "\n",
    "print(f\"score = {downsampled_lr.score(X_train_undersample, y_train_undersample)}\")\n",
    "logistic_regression.print_metrics(y_train_undersample, downsampled_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model score is slightly lower compared to SMOTE. <br>\n",
    "The metric scores are about the same compared to SMOTE but SMOTE looks slightly better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "X_col = X_train.columns\n",
    "X_df = pd.DataFrame(data=os_data_X, columns=X_col)\n",
    "y_df = pd.DataFrame(data=os_data_y, columns=['Sub'])\n",
    "\n",
    "# os_data_X_df.head()\n",
    "print(type(X_df))\n",
    "print(type(y_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58458, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y = os_data_y.reshape(-1,1)\n",
    "data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "endog must be in the unit interval.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9c2bb78e5d6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlogit_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# result = logit_model.fit()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# result.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/statsmodels/discrete/discrete_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m         if (not issubclass(self.__class__, MultinomialModel) and\n\u001b[1;32m    431\u001b[0m                 not np.all((self.endog >= 0) & (self.endog <= 1))):\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"endog must be in the unit interval.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: endog must be in the unit interval."
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(X_df[X_col], data_y).fit()\n",
    "# result = logit_model.fit()\n",
    "print(logit_model.summary2())\n",
    "# result.summary()\n",
    "\n",
    "# Create, fit model\n",
    "#     mod = sm.Logit(endog=y_train, exog=X_train)\n",
    "#     res = mod.fit(method='bfgs', maxiter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os_data_y.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False  True  True False  True False False  True\n",
      "  True False False False False False False  True False]\n",
      "[20  1  1  2  7 28 27 19  1 29  9  6  8 33 30 16 15 34 18 36 17 25 26 35\n",
      " 32  1 12 31 10  1  1 13  1 21  5  1  1  4 14 11 23 22 24  1  3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "rfe = RFE(logreg, 10)\n",
    "rfe = rfe.fit(os_data_X, os_data_y)\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)\n",
    "# rfe.get_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'campaign', 'pdays', 'previous', 'job_blue-collar',\n",
       "       'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired',\n",
       "       'job_self-employed', 'job_services', 'job_student', 'job_technician',\n",
       "       'job_unemployed', 'job_unknown', 'marital_married', 'marital_single',\n",
       "       'marital_unknown', 'education_high.school', 'education_illiterate',\n",
       "       'education_professional.course', 'education_university.degree',\n",
       "       'education_unknown', 'housing_unknown', 'housing_yes',\n",
       "       'default_unknown', 'default_yes', 'loan_unknown', 'loan_yes',\n",
       "       'contact_telephone', 'month_aug', 'month_dec', 'month_jul', 'month_jun',\n",
       "       'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sep',\n",
       "       'day_of_week_mon', 'day_of_week_thu', 'day_of_week_tue',\n",
       "       'day_of_week_wed', 'poutcome_nonexistent', 'poutcome_success'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os_data_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['campaign',\n",
       " 'pdays',\n",
       " 'job_retired',\n",
       " 'default_unknown',\n",
       " 'contact_telephone',\n",
       " 'month_aug',\n",
       " 'month_jul',\n",
       " 'month_may',\n",
       " 'month_nov',\n",
       " 'poutcome_nonexistent']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = zip(os_data_X.columns, rfe.support_)\n",
    "X_new_cols = [x[0] for x in col_list if x[1]==True]\n",
    "X_new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58458, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>default_unknown</th>\n",
       "      <th>contact_telephone</th>\n",
       "      <th>month_aug</th>\n",
       "      <th>month_jul</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>poutcome_nonexistent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.564625</td>\n",
       "      <td>-0.19645</td>\n",
       "      <td>-0.209108</td>\n",
       "      <td>-0.515042</td>\n",
       "      <td>-0.757855</td>\n",
       "      <td>-0.420234</td>\n",
       "      <td>-0.459331</td>\n",
       "      <td>-0.709185</td>\n",
       "      <td>-0.333783</td>\n",
       "      <td>-2.511053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.204519</td>\n",
       "      <td>-0.19645</td>\n",
       "      <td>-0.209108</td>\n",
       "      <td>-0.515042</td>\n",
       "      <td>-0.757855</td>\n",
       "      <td>-0.420234</td>\n",
       "      <td>2.177080</td>\n",
       "      <td>-0.709185</td>\n",
       "      <td>-0.333783</td>\n",
       "      <td>0.398239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.564625</td>\n",
       "      <td>-0.19645</td>\n",
       "      <td>-0.209108</td>\n",
       "      <td>-0.515042</td>\n",
       "      <td>1.319514</td>\n",
       "      <td>-0.420234</td>\n",
       "      <td>2.177080</td>\n",
       "      <td>-0.709185</td>\n",
       "      <td>-0.333783</td>\n",
       "      <td>0.398239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.155587</td>\n",
       "      <td>-0.19645</td>\n",
       "      <td>-0.209108</td>\n",
       "      <td>-0.515042</td>\n",
       "      <td>1.319514</td>\n",
       "      <td>-0.420234</td>\n",
       "      <td>-0.459331</td>\n",
       "      <td>-0.709185</td>\n",
       "      <td>-0.333783</td>\n",
       "      <td>0.398239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.564625</td>\n",
       "      <td>-0.19645</td>\n",
       "      <td>-0.209108</td>\n",
       "      <td>-0.515042</td>\n",
       "      <td>-0.757855</td>\n",
       "      <td>-0.420234</td>\n",
       "      <td>2.177080</td>\n",
       "      <td>-0.709185</td>\n",
       "      <td>-0.333783</td>\n",
       "      <td>0.398239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   campaign    pdays  job_retired  default_unknown  contact_telephone  \\\n",
       "0 -0.564625 -0.19645    -0.209108        -0.515042          -0.757855   \n",
       "1 -0.204519 -0.19645    -0.209108        -0.515042          -0.757855   \n",
       "2 -0.564625 -0.19645    -0.209108        -0.515042           1.319514   \n",
       "3  0.155587 -0.19645    -0.209108        -0.515042           1.319514   \n",
       "4 -0.564625 -0.19645    -0.209108        -0.515042          -0.757855   \n",
       "\n",
       "   month_aug  month_jul  month_may  month_nov  poutcome_nonexistent  \n",
       "0  -0.420234  -0.459331  -0.709185  -0.333783             -2.511053  \n",
       "1  -0.420234   2.177080  -0.709185  -0.333783              0.398239  \n",
       "2  -0.420234   2.177080  -0.709185  -0.333783              0.398239  \n",
       "3  -0.420234  -0.459331  -0.709185  -0.333783              0.398239  \n",
       "4  -0.420234   2.177080  -0.709185  -0.333783              0.398239  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = os_data_X[X_new_cols]\n",
    "print(X_new.shape)\n",
    "X_new.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.6940196380307229\n",
      "precision = 0.74\n",
      "recall = 0.59\n",
      "accuracy = 0.74\n",
      "f1 score = 0.66\n"
     ]
    }
   ],
   "source": [
    "#Try applying new feature list into vanilla regression\n",
    "\n",
    "rfe_lr = LogisticRegression(C = 1e9, solver='newton-cg',class_weight='balanced',max_iter=1000)\n",
    "rfe_lr.fit(X_new, os_data_y)\n",
    "\n",
    "rfe_pred = rfe_lr.predict(X_new)\n",
    "\n",
    "print(f\"score = {rfe_lr.score(X_new, os_data_y)}\")\n",
    "logistic_regression.print_metrics(os_data_y, rfe_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.581016\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                58458\n",
      "Model:                          Logit   Df Residuals:                    58448\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Mon, 21 Oct 2019   Pseudo R-squ.:                  0.1618\n",
      "Time:                        22:00:59   Log-Likelihood:                -33965.\n",
      "converged:                       True   LL-Null:                       -40520.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "campaign                -0.1951      0.012    -15.938      0.000      -0.219      -0.171\n",
      "pdays                    0.5067      0.013     40.094      0.000       0.482       0.531\n",
      "job_retired              0.1292      0.009     14.728      0.000       0.112       0.146\n",
      "default_unknown         -0.2361      0.011    -22.331      0.000      -0.257      -0.215\n",
      "contact_telephone       -0.5355      0.012    -46.198      0.000      -0.558      -0.513\n",
      "month_aug               -0.4007      0.011    -35.935      0.000      -0.423      -0.379\n",
      "month_jul               -0.4042      0.011    -35.159      0.000      -0.427      -0.382\n",
      "month_may               -0.4423      0.012    -37.312      0.000      -0.466      -0.419\n",
      "month_nov               -0.3749      0.011    -35.472      0.000      -0.396      -0.354\n",
      "poutcome_nonexistent     0.0697      0.011      6.449      0.000       0.049       0.091\n",
      "========================================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "logit_model = sm.Logit(os_data_y, X_new)\n",
    "result = logit_model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To get our baseline, we'll do a 'vanilla' case - no regularization.\n",
    "## In this case, we do not scale our data\n",
    "logreg_vanilla = LogisticRegression(C=1e9, solver='newton-cg')\n",
    "logreg_vanilla.fit(os_data_X, os_data_y)\n",
    "y_hat_vanilla = logreg_vanilla.predict(X=os_data_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision = 0.86\n",
      "recall = 0.86\n",
      "accuracy = 0.86\n",
      "f1 score = 0.86\n"
     ]
    }
   ],
   "source": [
    "print_metrics(os_data_y, y_hat_vanilla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logistic_regression as lr\n",
    "# vanilla_result = lr.cross_validation(n=10, shuffle=True, lr='vanilla', X_train=os_data_X, y_train=os_data_y)\n",
    "# vanilla_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l2_result = lr.cross_validation(n=10, shuffle=True, lr='l2', X_train=os_data_X, y_train=os_data_y)\n",
    "# l2_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = LogisticRegression(C=1, solver='newton-cg', class_weight='balanced', max_iter=1000)\n",
    "l2_reg.fit(os_data_X, os_data_y)\n",
    "l2_reg_prd = l2_reg.predict(os_data_X)\n",
    "print_metrics(os_data_y, l2_reg_prd,lr_reg=l2_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_reg = LogisticRegression(C=1, solver='saga',penalty='l1', max_iter=1000)\n",
    "l1_reg.fit(os_data_X, os_data_y)\n",
    "l1_reg_prd = l1_reg.predict(os_data_X)\n",
    "print_metrics(os_data_y, l1_reg_prd, lr_reg=l1_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_result = lr.cross_validation(n=10, shuffle=True, lr='l1', X_train=os_data_X, y_train=os_data_y)\n",
    "l1_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean\n",
    "print('vanilla regularization', vanilla_result.mean(axis=0))\n",
    "print('l1 regularization', l1_result.mean(axis=0))\n",
    "print('l2 regularixation', l2_result.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the std\n",
    "print('vanilla regularization', vanilla_result.std(axis=0))\n",
    "print('l1 regularization', l1_result.std(axis=0))\n",
    "print('l2 regularixation', l2_result.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_df = pd.DataFrame(data=y_hat, columns=['y_hat'])\n",
    "y_hat_df.y_hat.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_posetive = np.count_nonzero(y_hat)\n",
    "accuracy = true_posetive/len(y_hat)\n",
    "print('accuracy', accuracy)\n",
    "print('values', len(y_hat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Modify data for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummed_train = pd.get_dummies(X_train, \n",
    "               columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'season', 'day_of_week', 'poutcome'], \n",
    "               drop_first= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummed_train.head()\n",
    "print(dummed_train.shape)\n",
    "print(dummed_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate for age\n",
    "mu, std = dummed_train.age.mean(), dummed_train.age.std()\n",
    "print('mean age', mu, 'age std', std)\n",
    "print('Standardized value for the first row is:', (dummed_train.age[1233]-mu)/std)\n",
    "print(dummed_train.age[1233])\n",
    "dummed_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To get our baseline, we'll do a 'vanilla' case - no regularization.\n",
    "## In this case, we do not scale our data\n",
    "logreg = LogisticRegression(class_weight='balanced', solver='newton-cg')\n",
    "logreg.fit(dummed_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logreg.score(dummed_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Standard Scaler to be used within pipelines.  \n",
    "class StScaler(StandardScaler):\n",
    "    def fit_transform(slf,X,y=None):\n",
    "        print(f\"transformed rows: {len(X)}\")\n",
    "        return super().fit_transform(X,y)\n",
    "\n",
    "#Using pipeline to avoid data leakage within CV process \n",
    "pipe = Pipeline([\n",
    "    ('scaler', StScaler()),\n",
    "    ('logreg', LogisticRegression(C = 1e9, \n",
    "                                 solver = 'newton-cg',\n",
    "                                 max_iter = 1000,\n",
    "                                 class_weight = 'balanced'))\n",
    "])\n",
    "\n",
    "print(f\"train data length: {len(dummed_train)} rows\")\n",
    "print(cross_val_score(pipe,dummed_train,y_train, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearchCV for parameter tuning\n",
    "\n",
    "# param_grid = {''}\n",
    "\n",
    "# search = GridSearchCV(estimator=pipe,\n",
    "#                       cv=5,\n",
    "#                       param_grid=\n",
    "#                       return_train_score=True)\n",
    "\n",
    "# search.fit(X_train, y_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
